
## 툴 데코레이터는 어떻게 툴을 변환시키나  

### 코드  

```python
from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
import os
from config.config import config

def get_model(model:str="gpt-4o-mini", api_key:str|None=None):
    if api_key is None:
        os.environ["OPENAI_API_KEY"] = config.get("apikey", "openai")
    model = ChatOpenAI(model=model)
    return model

from langchain_core.tools import tool
from datetime import datetime
import pytz

@tool
def get_current_time(timezone:str, location:str) -> str:
    """ 현재 시각을 반환하는 함수

    Args:
        timezone (str): 타임존(예: 'Asia/Seoul'). 실제 존재해야 함
        location (str): 지역명. 타임존은 모든 지명에 대응되지 않으므로 이후 llm 답변 생성에 사용됨
    """
    tz = pytz.timezone(timezone)
    now = datetime.now(tz).strftime("%Y-%m-%d %H:%M:%S")
    location_and_local_time = f"{timezone} ({location}) 현재 시각 : {now}"
    return location_and_local_time

# messages
messages = [
    SystemMessage("당신은 사용자의 질문에 답변하기 위해 tools를 사용할 수 있습니다."),
    HumanMessage("하와이와 부산은 지금 몇시잉교?")
]

# llm_with_tools 를 사용해 사용자 질문에 대한 답변 생성
response = llm_with_tools.invoke(messages)
messages.append(response)

for tool_call in response.tool_calls:
    selected_tool = tool_dict[tool_call["name"]]
    tool_msg = selected_tool.invoke(tool_call)
    messages.append(tool_msg)

print(messages)
```

```bash
[
    SystemMessage(content='당신은 사용자의 질문에 답변하기 위해 tools를 사용할 수 있습니다.', additional_kwargs={}, response_metadata={}),
    HumanMessage(content='하와이와 부산은 지금 몇시잉교?', additional_kwargs={}, response_metadata={}),
    AIMessage(content='', ... tool_calls=[
        {'name': 'get_current_time', 'args': {'timezone': 'Pacific/Honolulu', 'location': '하와이'}},
        {'name': 'get_current_time', 'args': {'timezone': 'Asia/Seoul', 'location': '부산'}}
    ]),
    ToolMessage(content='Pacific/Honolulu (하와이) 현재 시각 : 2026-01-31 04:58:39', name='get_current_time', tool_call_id='call_***'),
    ToolMessage(content='Asia/Seoul (부산) 현재 시각 : 2026-01-31 23:58:39', name='get_current_time', tool_call_id='call_***')
]
```


- 어떻게 selected_tool 에 invoke 메서드가 있을 수 있을까?    
- 정답은 바로 `@tool` 데코레이터이다.  

### `@tool` 데코레이터의 작동 방식  

LangChain의 @tool 데코레이터는 일반적인 파이썬 함수를 감싸서 BaseTool 객체로 변환하는 마법을 부립니다. 이 과정을 통해 함수는 단순한 실행 단위를 넘어, LLM이 이해할 수 있는 인터페이스와 실행 로직을 갖춘 객체가 됩니다.  

구체적인 작동 방식을 세 가지 핵심 단계로 정리해 드립니다. 

#### 1. 함수 정보 추출 (Introspection)  

데코레이터가 호출되는 순간, 파이썬의 타입 힌트와 docstring을 분석합니다.  

- 함수 이름: get_current_time이 툴의 식별자가 됩니다.  
- Docstring: 함수의 설명이 모델에게 전달될 description으로 변환됩니다. LLM은 이 설명을 보고 "이 툴이 지금 상황에 필요한가?"를 판단합니다.  
- Args Schema: timezone: str과 같은 타입 힌트를 바탕으로 Pydantic 모델을 자동 생성합니다. 이는 LLM이 도구에 인자를 전달할 때 형식을 맞추도록 강제하는 가이드라인이 됩니다.

#### 2. BaseTool 객체로의 래핑 (Wrapping)  

@tool은 함수를 AnnotatedTool 혹은 StructuredTool이라는 클래스의 인스턴스로 변환합니다.  

- 속성 부여: 함수는 이제 .name, .description, .args_schema 같은 속성을 가집니다.  
- 인터페이스 통일: 모든 툴이 동일한 부모 클래스(BaseTool)를 상속받게 되므로, LangChain 내부 어디서든 일관된 방식으로 다룰 수 있습니다.  

#### 3. invoke 메서드 구현  

질문하신 **"어떻게 invoke 메서드가 있을 수 있는가"**에 대한 직접적인 해답입니다.  

@tool에 의해 변환된 객체는 LangChain의 Runnable 인터페이스를 구현합니다. 이 인터페이스는 표준화된 실행 메서드인 invoke를 포함하고 있습니다.  

- (1) 입력 수신: tool_call 데이터(JSON 형태의 인자)가 invoke에 전달됩니다.  
- (2) 유효성 검사: 생성된 Pydantic 스키마를 바탕으로 인자가 올바른지 체크합니다.  
- (3) 원본 함수 실행: 검증이 끝나면 비로소 우리가 작성한 파이썬 함수 본체를 실행합니다.  
- (4) 결과 반환: 실행 결과를 ToolMessage 형태로 포장하여 반환합니다.  

### 요약: 변환 과정의 시각적 흐름  

|단계|구성 요소|역할|
|---|---|---|
|Input|일반 파이썬 함수|비즈니스 로직 수행|
|Analysis|Type Hints & Docstring|LLM을 위한 스키마(JSON Schema) 생성|
|Putput|BaseTool 인스턴스|invoke, batch, stream 등 메서드 보유|

결과적으로 selected_tool.invoke(tool_call)를 호출할 수 있는 이유는, @tool이 당신의 함수를 표준화된 인터페이스를 가진 도구 객체로 업그레이드해주었기 때문입니다.  

