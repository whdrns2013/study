
## ìŠ¤íŠ¸ë¦¼ë¦¿ì— êµ¬í˜„í•˜ê¸°   

### ë­ì²´ì¸ ë©”ëª¨ë¦¬ì— ê¸°ë°˜í•œ ë©€ë¦¬í„´ ì±—ë´‡ ë§Œë“¤ê¸°  

```python
import streamlit as st
from config.config import config
from core.openai_model import get_model
from tools.generate_chat_id import generate_chat_id
from langchain_openai import ChatOpenAI
from langchain_core.chat_history import InMemoryChatMessageHistory, BaseChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

def get_session_history(session_id:str) -> BaseChatMessageHistory:
    if session_id not in st.session_state["store"]:
        st.session_state["store"][session_id] = InMemoryChatMessageHistory()
    return st.session_state["store"][session_id]

def streamlit_chat(stream=config.getboolean("setting", "mode.stream")):
    
    # ì‚¬ì´ë“œë°” : 
    with st.sidebar:
        "Streamlit í…ŒìŠ¤íŠ¸"
    
    # title
    st.title("ğŸ¤– Doit Chatbot")
    
    # ì´ˆê¸° ë©”ì‹œì§€
    if "messages" not in st.session_state: # st.session_state : ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ì‚¬ìš©ìì˜ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
        st.session_state["messages"] = [SystemMessage("ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤.")]
        st.session_state["messages"].append(AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"))
    
    # ëŒ€í™” ì„¸ì…˜ ìŠ¤í† ì–´ ìƒì„±
    if "store" not in st.session_state:
        st.session_state["store"] = {}
    
    llm = get_model()
    with_message_history = RunnableWithMessageHistory(llm, get_session_history)
    
    # ì„¸ì…˜ ìŠ¤í† ì–´ì—ì„œ í˜„ì¬ ì„¸ì…˜idë¥¼ ì°¾ê³ , ì—†ìœ¼ë©´ ìƒì„±
    session_id = ""
    if "session_id" not in st.session_state:
        session_id = generate_chat_id()
        st.session_state["session_id"] = session_id
    model_config = {"configurable":{"session_id":session_id}}
    
    # ëŒ€í™” ê¸°ë¡ì„ ì›¹ë¸Œë¼ìš°ì €ì— ì¶œë ¥
    for mgs in st.session_state.messages:
        if mgs:
            if (isinstance(mgs, SystemMessage)) and (config.getboolean("setting", "mode.debug")):
                st.chat_message("system").write(mgs.content)
            if isinstance(mgs, AIMessage):
                st.chat_message("assistant").write(mgs.content)
            if isinstance(mgs, HumanMessage):
                st.chat_message("user").write(mgs.content)
    
    # LLM ì— ì§ˆì˜
    if prompt := st.chat_input(): # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ prompt ë³€ìˆ˜ì— í• ë‹¹
        user_message = HumanMessage(prompt)
        st.session_state.messages.append(user_message)
        st.chat_message("user").write(prompt)
        
        # ì§ˆì˜ì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜´
        response = None
        content = None
        if stream:
            response_chunk = with_message_history.stream(user_message, config=model_config)
            response = None
            with st.chat_message("assistant").empty():
                for r in response_chunk:
                    if response is None:
                        response = r
                    else:
                        response += r
                    st.markdown(response.content)
            content = response.content
        else:
            response = with_message_history.invoke(user_message, config=model_config)
            content = response.content
            st.chat_message("assistant").write(content)
        st.session_state.messages.append(response)
        st.session_state.messages.append({"role":"assistant", "content":content})
    
# streamlit ì‹¤í–‰
# uv run streamlit run main.py
```

#### ê²¹ì¹˜ì§€ ì•ŠëŠ” session id ë§Œë“¤ê¸°  

> ì´ê±° ì›ë¦¬ ê³µë¶€í•˜ê¸°  
> ë²ˆì™¸ 05  

```python
import uuid

def generate_chat_id() -> str:
    return str(uuid.uuid4())
```

### ë­ì²´ì¸ ë©”ëª¨ë¦¬ ì—†ì´ ë©€í‹°í„´ ë§Œë“¤ê¸°  

- ì´ ë§ì€ ê³§ ì§ì ‘ ë¦¬ìŠ¤íŠ¸, ë°ì´í„°ë² ì´ìŠ¤ ë“±ì„ ì´ìš©í•´ íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•œë‹¤ëŠ” ëœ»ì´ë‹¤.  
- ê¸°ì¡´ì˜ langchain + streamlit ì½”ë“œì—ì„œ ìˆ˜ì •ì„ í•œë‹¤.  

```python
import streamlit as st
from config.config import config
from core.openai_model import get_model
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage
from tools.langchain_tools import tools, tool_dict

def get_ai_response(llm, messages, stream):
    if stream:
        return llm.stream(messages)
    else:
        response = llm.invoke(messages)
        return response

def streamlit_chat(stream=config.getboolean("setting", "mode.stream")):
    
    # ì‚¬ì´ë“œë°” : 
    with st.sidebar:
        "Streamlit í…ŒìŠ¤íŠ¸"
    
    # title
    st.title("ğŸ¤– Doit Chatbot")
    
    # ëª¨ë¸ ì„ ì–¸
    llm = get_model()
    
    # ì´ˆê¸° ë©”ì‹œì§€
    if "messages" not in st.session_state: # st.session_state : ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ì‚¬ìš©ìì˜ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
        st.session_state.messages = [SystemMessage("ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤.")]
        st.session_state.messages.append(AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"))
    
    # ëŒ€í™” ê¸°ë¡ì„ ì›¹ë¸Œë¼ìš°ì €ì— ì¶œë ¥
    for msg in st.session_state.messages:
        if msg:
            if (isinstance(msg, SystemMessage)) and (config.getboolean("setting", "mode.debug")):
                st.chat_message("system").write(msg.content)
                st.chat_message("tool").write(msg.content)
            if isinstance(msg, AIMessage):
                st.chat_message("assistant").write(msg.content)
            if isinstance(msg, HumanMessage):
                st.chat_message("user").write(msg.content)
    
    # LLM ì— ì§ˆì˜
    if prompt := st.chat_input(): # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ prompt ë³€ìˆ˜ì— í• ë‹¹
        user_message = HumanMessage(prompt)
        st.session_state.messages.append(user_message)
        st.chat_message("user").write(prompt)
        
        # ì§ˆì˜ì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜´
        if stream:
            response_gen = get_ai_response(llm, st.session_state.messages, stream)
            result = st.chat_message("assistant").write_stream(response_gen) # write_stream ì€ ì¶œë ¥ + ë¬¸ìì—´ ë°˜í™˜
        else:
            response = get_ai_response(llm, st.session_state.messages, stream)
            result = response.content
            st.chat_message("assistant").write(result) # write : ì¶œë ¥ë§Œ í•¨ (ë°˜í™˜ ì—†ìŒ)
        
        st.session_state.messages.append(AIMessage(result))
    
# streamlit ì‹¤í–‰
# uv run streamlit run main.py
```

### ë„êµ¬ë¥¼ ì¶”ê°€í•˜ê³  ìŠ¤íŠ¸ë¦¼ ë°©ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ê¸°  

