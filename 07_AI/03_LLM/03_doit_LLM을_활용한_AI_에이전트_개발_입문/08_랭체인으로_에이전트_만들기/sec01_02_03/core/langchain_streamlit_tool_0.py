import streamlit as st
from config.config import config
from core.openai_model import get_model
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

def get_ai_response(llm, messages, stream):
    if stream:
        # response = llm.stream(messages)
        # for chunk in response:
        #     yield chunk
        return llm.stream(messages)
    else:
        response = llm.invoke(messages)
        return response

def streamlit_chat(stream=config.getboolean("setting", "mode.stream")):
    
    # ì‚¬ì´ë“œë°” : 
    with st.sidebar:
        "Streamlit í…ŒìŠ¤íŠ¸"
    
    # title
    st.title("ğŸ¤– Doit Chatbot")
    
    # ëª¨ë¸ ì„ ì–¸
    llm = get_model()
    
    # ì´ˆê¸° ë©”ì‹œì§€
    if "messages" not in st.session_state: # st.session_state : ìŠ¤íŠ¸ë¦¼ë¦¿ì—ì„œ ì‚¬ìš©ìì˜ ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
        st.session_state.messages = [SystemMessage("ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ëŠ” AI ì±—ë´‡ì…ë‹ˆë‹¤.")]
        st.session_state.messages.append(AIMessage("ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"))
    
    # ëŒ€í™” ê¸°ë¡ì„ ì›¹ë¸Œë¼ìš°ì €ì— ì¶œë ¥
    for mgs in st.session_state.messages:
        if mgs:
            if (isinstance(mgs, SystemMessage)) and (config.getboolean("setting", "mode.debug")):
                st.chat_message("system").write(mgs.content)
            if isinstance(mgs, AIMessage):
                st.chat_message("assistant").write(mgs.content)
            if isinstance(mgs, HumanMessage):
                st.chat_message("user").write(mgs.content)
    
    # LLM ì— ì§ˆì˜
    if prompt := st.chat_input(): # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ prompt ë³€ìˆ˜ì— í• ë‹¹
        user_message = HumanMessage(prompt)
        st.session_state.messages.append(user_message)
        st.chat_message("user").write(prompt)
        
        # ì§ˆì˜ì— ëŒ€í•œ ì‘ë‹µ ë°›ì•„ì˜´
        if stream:
            response_gen = get_ai_response(llm, st.session_state.messages, stream)
            result = st.chat_message("assistant").write_stream(response_gen) # write_stream ì€ ì¶œë ¥ + ë¬¸ìì—´ ë°˜í™˜
        else:
            response = get_ai_response(llm, st.session_state.messages, stream)
            result = response.content
            st.chat_message("assistant").write(result) # write : ì¶œë ¥ë§Œ í•¨ (ë°˜í™˜ ì—†ìŒ)
        
        st.session_state.messages.append(AIMessage(result))
    
# streamlit ì‹¤í–‰
# uv run streamlit run main.py
