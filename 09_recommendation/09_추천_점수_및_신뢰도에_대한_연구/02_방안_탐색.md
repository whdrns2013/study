
## 개요  

- 점수 교정 방법 : 추천 점수를 변환하여 사용자에게 신뢰도를 전달하는 방안  
- 추천 점수와는 별도의 신뢰도(적합도) 도입   


## 점수 교정 (Calibration)  

단순한 선형 정규화의 한계를 극복하기 위해 가장 권장되는 방안은 '확률 교정(Probability Calibration)'을 도입하는 것이다. 교정은 모델이 출력하는 점수가 실제 해당 아이템이 사용자에게 적합할 확률과 일치하도록 조정하는 과정이다. 예를 들어, 교정된 점수가 0.7이라면, 실제로 그러한 추천이 70%의 확률로 사용자 만족을 이끌어내야 함을 의미한다.   

### (★) 주요 교정 알고리즘  

- 플랫 스케일링(Platt Scaling) : 플랫 스케일링은 모델의 원시 점수를 독립 변수로, 실제 정답 여부(클릭, 수강 등)를 종속 변수로 하는 로지스틱 회귀 모델을 학습시킨다. 이는 점수를 0~1 사이의 확률 값으로 매핑할 수 있으며, 특히 서포트 벡터 머신(SVM)과 같이 점수 기반 출력을 내는 모델에 효과적이다.  

- 이소토닉 회귀(Isotonic Regression) : 이소토닉 회귀는 추천 점수와 실제 확률 사이의 관계를 비내림차순 함수로 적합시키는 비모수적 방법이다. 데이터가 충분할 경우 플랫 스케일링보다 정교한 교정이 가능하지만, 데이터가 적을 경우 과적합의 위험이 있다.  

- (★) 온도 스케일링(Temperature Scaling) : 온도 스케일링은 신경망 기반 모델의 로짓(Logits)을 파라미터 $T$로 나누어 소프트맥스 함수의 선명도를 조절하는 방식이다. 이는 모델의 내부 구조를 크게 바꾸지 않으면서도 전반적인 확신 수준을 조정하는 데 유용하다.  

### 전역 정규화(Global Normalization)   

로컬 민맥스(Local Min-Max)가 현재 추천 리스트 내의 최소/최대를 기준으로 삼는다면, 전역 정규화는 전체 서비스 기간 또는 전체 아이템 풀에서의 역사적 최소/최대치를 기준으로 삼는다.  

$ x_{global}' = \frac{x - \min(Global)}{\max(Global) - \min(Global)} $  

이 방식을 사용하면, 모든 후보 아이템이 역사적 기준에서 평범한 수준이라면 정규화된 점수 역시 0.4나 0.5 수준에서 머물게 된다. 이는 사용자가 보는 "추천 점수"가 시기에 상관없이 일관된 의미를 갖게 함으로써, 계절학기에도 점수가 낮게 나오는 현상을 자연스럽게 수용할 수 있게 해준다.

## 상대평가 왜곡 방지를 위한 휴리스틱 보정  

> 휴리스틱 : 불확실하거나 시간이 제한된 상황에서 정보에 입각한 꼼꼼한 분석 대신, 경험과 직관에 의존해 빠르게 합리적인 만족할 만한 답을 찾는 '어림짐작' 혹은 '간편 추론법'  

### (★) 가상 아이템(Dummy Item) 삽입을 통한 상대평가 보정   

추천 후보군에 의도적으로 품질이 고정된 가상 아이템(더미 아이템)를 포함시킨 후 정규화를 수행한다.  
더미 아이템은 전체 데이터의 평균을 가지거나, 전체 데이터 중 가장 낮은 혹은 가장 높은 추천점수를 가지게 할 수도 있다.  

- 방법: 모든 사용자에게 공통적으로 매우 낮은 점수(또는 평균 혹은 아주 높은 점수)를 갖는 '더미 아이템'를 포함하여 MinMax를 계산한다.  
- 효과: 실제 아이템들의 점수가 전체적으로 낮다면, MinMax 이후에도 1.0에 도달하지 못하고 0.3 ~ 0.4 수준에 머물게 된다.   
- 효과: 실제 아이템들의 점수가 전체적으로 낮다면, 더미 아이템이 $\min$ 값을 점유하더라도 분모가 커지거나 분자가 작게 유지되어 리스트 1순위 아이템이 강제로 1.0에 도달하는 현상을 방지할 수 있다.  

### 점수 계산 방식 개선  

- MinMax Scaling의 한계를 극복하기 위해 점수 산출 로직을 다음과 같이 변경해 보는 것  
- Softmax 함수 또는 sigmoid 함수 등  

#### Softmax 함수 활용  

- Softmax 함수를 사용해 추천 점수를 확률 분포 형태로 변환  
- Softmax : 각 아이템의 raw 점수 $\exp(s_i)$를 계산한 뒤, 총합으로 나눠 졍규화 -> 모든 추천 점수의 합이 1이 되는 확률분포  
- 정말 강력한 후보가 있는 경우 확률이 높게(e.g. 0.9) 나올 수 있지만, 모든 후보의 raw 점수가 비슷한 경우, 최고 항목도 0.2 정도에 그칠 수 있음  
- 현재 추천들의 확신 수준이 낮다는 정보를 간접적으로 제공할 수 있으나  
- 현재 추천 점수의 의미가 변하며, 매우 낮은 추천점수로 제공될 가능성이 있다고 생각됨  

#### sigmoid 함수 활용  

Sigmoid는 특정 값 이상의 점수에 대해서만 1에 수렴하게 만든다.  
적용 아이디어: 모델의 출력값을 특정 함수에 통과시켜, 정말 좋은 아이템일 때만 0.9 이상의 높은 점수가 나오도록 설계한다.  


## 절대적인 추천 점수(혹은 확률) 도입  

- Min-Max와 같은 상대 점수 대신, 절대적 기준의 점수 체계로 전환  
- "사용자가 그 아이템을 좋아할 확률" 또는 "예상 평점"과 같은 절대 지표를 사용  
- 예를 들어 현재 앙상블의 출력이 "아이템을 클릭할 확률"로 직접 해석되도록 모델을 보정(calibration)해, 실제 확률이 0.3이면 0.3 (30%)로 표시  
- 다만 현재 구조에서 이를 구현하려면, 각 하위 모델의 출력부터 앙상블까지 일관된 확률적 의미를 갖도록 재학습 또는 보정해야 함(큰 노력이 필요함)  
- 현실적으로는 별도의 **메타 모델(스태킹)**을 도입해 4개 모델의 출력을 입력으로 받고 실제 클릭/관심 여부를 이진 분류하여 확률을 예측하도록 학습시키는 방법도 고려해볼 수 있음  

## 신뢰도 기반 동적 앙상블 및 UI/UX 전략  

### (★) 신뢰도 산출 근거  

아이템 점수와 별개로 **"추천 신뢰도(Confidence Score)"**를 별도로 계산하여 병행 노출하는 방법  
해당 추천 또는 특정 상황에서 얼마나 자신 있게 예측(추천)하고 있는지를 반영하는 지표  

- 데이터 기반 신뢰도 : 예를 들어 협업필터링에서는 일반적으로 사용자가 많은 아이템을 평가할수록, 아이템에 평가자 수가 많을수록 해당 예측에 대한 신뢰도가 높아짐  
- 앙상블 기반 신뢰도 : 앙상블 내 모델들의 의견 일치 정도를 신뢰도로 볼 수도 있음 (e.g. 만약 한두 모델만 해당 아이템에 높게 점수를 매겼다면 불확실한 추천 / 모든 모델이 높게 점수를 준다면 신뢰도가 높다)  

### 모델별 국소적 신뢰도(Local Confidence) 산출  

- 분산 기반 신뢰도 : 행렬 분해(Matrix Factorization) 모델에서 사용자 및 아이템 잠재 요인의 분산 파라미터를 도입하여 예측값의 신뢰 구간을 계산한다.     
- 엔트로피 기반 신뢰도 : 모델이 출력하는 확률 분포의 엔트로피를 측정하여, 점수가 특정 아이템에 집중되지 않고 고르게 퍼져 있다면 해당 모델의 예측 신뢰도를 낮게 평가한다.    
- 프로필 크기 비례 가중치 : 사용자의 과거 활동 데이터(예: 이전에 수강한 과목 수)가 적을수록 협업 필터링 모델의 신뢰도는 낮아지며, 이때는 콘텐츠 기반 모의 가중치를 동적으로 높여야 한다.  

### UI/UX 신뢰도 표현 전략  

사용자에게 "추천 점수"를 어떻게 보여줄 것인가는 시스템의 신뢰도와 직결된다. 민맥스 정규화로 인해 발생하는 "모든 1순위가 1.0점으로 보이는 문제"는 수치 중심의 UI에서 가치 중심의 UI로 전환함으로써 해결할 수 있다.  

- 추천 점수 옆에 신뢰도를 함께 표시  
- e.g. 별 모양이나 막대로 “신뢰도: ★☆☆” 등을 표기해 최고점=100%로 오해하는 것을 방지  
- 주의할 점은 예측 점수(선호도)와 신뢰도는 다른 개념이라는 점  

#### 신뢰도 시각화 패턴(CVP) 도입  

단순한 숫자(1.0, 0.9) 대신 의미론적 레이블과 시각적 지표를 활용하는 것이 바람직하다.   

- 범주형 신뢰도 레이블: 점수가 0.8 이상일 때는 "매우 추천", 0.5~0.8일 때는 "적정 매칭", 0.5 미만일 때는 "관심 있을 만한 대안" 등으로 표기한다. 이를 통해 사용자는 현재 추천되는 과목이 시스템이 강력하게 확신하는 것인지, 아니면 차선책으로 제시하는 것인지를 직관적으로 파악할 수 있다.   

- 불확실성 구간 표시: 점수 하나만 보여주는 것이 아니라, 해당 추천의 점수 범위를 막대 그래프 형태로 보여주어 시스템의 확신 수준을 전달한다.   

- 색상 코딩: 신뢰 수준에 따라 녹색(높음), 주황색(중간), 회색(낮음) 등으로 아이콘이나 배경색을 차별화한다. 단, 낮은 신뢰도가 사용자에게 공포감을 주지 않도록 디자인에 주의해야 한다.   

#### 추천의 근거 제시  

사용자는 점수 그 자체보다 "왜 이 과목이 추천되었는가"에 더 민감하게 반응한다.   

- 로컬 설명(Local Explanation): 특정 아이템이 추천된 이유를 설명한다. "귀하의 전공 필수 학점 충족을 위해 추천합니다" 또는 "비슷한 진로를 희망하는 선배들이 많이 들었습니다"와 같은 메시지는 낮은 점수의 추천이라도 사용자가 납득하게 만든다.   

- 글로벌 설명(Global Explanation): 시스템이 전반적으로 어떤 기준으로 과목을 선정하는지 공지한다. "현재 계절학기 개설 과목 중 귀하의 관심사와 가장 일치하는 과목들을 보여드립니다"라는 문구는 후보군이 제한적이라는 맥락을 사용자에게 이해시킨다.   


### 임계값(스레숄드) 기반의 필터링 및 폴백(Fallback) 전략  

#### 절대적 임계값(Hard Threshold) 설정  

앙상블 결과 산출된 최종 점수가 특정 기준치 $T$에 미달할 경우, 이를 "유효한 추천"으로 간주하지 않는 논리가 필요하다.  

- 정밀도 우선 전략 : 교육 환경에서는 부적절한 과목을 추천하는 것의 기회비용이 크므로, 임계값을 다소 높게(예: 교정 확률 0.6 이상) 설정하여 확실한 것만 추천 리스트에 올린다. 
- 동적 임계값 : 계절학기처럼 평균적인 점수가 낮게 형성되는 시기에는 임계값을 유연하게 조정하되, 추천의 성격을 "개인화된 추천"에서 "탐색적 제안"으로 변경하여 고지한다. 

#### 폴백(Fallback) 컨텐츠 제공  

사용자 맞춤형 추천 결과가 기준 미달일 경우, 시스템이 미리 정의한 '인기 항목'이나 '필수 항목'을 대신 보여준다.  

예시: 전공 과목 추천이 없을 경우, 교양 필수나 인기 있는 일반 선택 과목을 추천하여 빈 화면을 방지한다.  

#### 계층적 폴백  

추천 엔진이 유효한 결과를 내지 못할 때의 시나리오를 설계해야 한다. 

- 1단계 : 개인화 추천 : 신뢰도가 높은 아이템이 있을 때만 노출. 
- 2단계 : 맥락적 대안 : 전공 과목이 없으면 "전공 관련 교양" 또는 "지난 학기 인기 과목" 노출. 
- 3단계 : 시스템 메시지 및 도움말 : "현재 귀하의 전공과 일치하는 과목이 개설되지 않았습니다. 다른 전공의 기초 과목이나 교양 과목을 탐색해보시겠습니까?"라는 안내와 함께 수강 편람 링크 제공. 
- 4단계 : 침묵 전략 : 적절한 제안이 전혀 없을 때는 추천 영역을 아예 숨기는 것이 사용자의 인지 부하를 줄이고 시스템의 신뢰를 유지하는 방법이다.


## 앙상블 모델 개선을 위한 향후 과제  

현재의 가중치 소프트 보팅 구조를 유지하면서도 점수 왜곡을 근본적으로 해결하기 위해서는 정규화 이후의 프로세스뿐만 아니라 학습 단계에서의 개선이 병행되어야 한다.   

### 스태킹(Stacking) 메타 모델의 도입  

단순한 가중 합산 대신, 각 하위 모델의 출력값들과 사용자/아이템의 컨텍스트(계절 정보, 학년, 전공 등)를 입력으로 받아 최종 점수를 예측하는 별도의 '메타 모델'을 학습시킨다. 이 메타 모델은 "여름 방학에는 모델 A의 점수가 평소보다 신뢰도가 낮다"는 패턴을 스스로 학습하여 가중치를 조절할 수 있게 된다.   

### 손실 함수(Loss Function)의 재설계

단순히 클릭 여부나 평점을 예측하는 것을 넘어, 점수 사이의 상대적 순위를 최적화하는 '쌍체 학습(Pairwise Learning)'이나 '리스트 학습(Listwise Learning)' 손실 함수를 도입하여 변별력을 높여야 한다. 특히 NDCG(Normalized Discounted Cumulative Gain)와 같은 지표를 최적화 목표로 삼으면, 상위 아이템의 배치 순서뿐만 아니라 그 품질의 상대적 우수성을 더 잘 보존할 수 있다.   


## 논문  

### Guo et al. (2017), "On Calibration of Modern Neural Networks"  

핵심 내용: 현대적인 신경망 모델들이 높은 정확도에도 불구하고 점수(확률)가 왜곡되어(Miscalibrated) 나타나는 현상을 분석한 기념비적인 논문. 이 논문에서 제안된 '온도 스케일링(Temperature Scaling)'은 민맥스 정규화의 대안으로 점수 분포를 실제 신뢰도와 일치시키는 데 표준적으로 사용됨.  

[https://arxiv.org/abs/1706.04599](https://arxiv.org/abs/1706.04599)  

### 권원빈 (2024), Confidence Calibration for Recommender Systems and Its Applications (추천 시스템을 위한 신뢰도 보정 및 활용)  

핵심 내용: 일반적인 추천 시스템이 아이템 목록만 제공할 뿐 신뢰도를 명시하지 않는 문제를 지적하며, 추천 결과의 신뢰도를 보정하는 방법론과 이를 실제 응용에 활용하는 방안을 다룬다. 사용자가 추천 결과에 대해 갖는 '신뢰의 정도'를 수치화하는 연구로, 질문하신 민맥스 점수 왜곡 문제를 해결할 가장 직접적인 이론적 배경을 제공한다.  
박사 학위 논문

[https://arxiv.org/abs/2402.16325](https://arxiv.org/abs/2402.16325)  

### Zhefan Wang (2024), To Recommend or Not: Recommendability Identification in Conversations with Pre-trained Language Models  

핵심 내용: 사용자가 특정 시점에 추천 결과를 정말로 필요로 하는지, 혹은 시스템이 유의미한 추천을 내놓을 수 있는 상황인지를 판단하는 '추천 가능성 식별(Recommendability Identification)' 문제를 정의한다. 아이템이 부족한 계절학기 같은 상황에서 시스템이 '침묵'하거나 다른 대안을 찾아야 하는 시점을 결정하는 이론적 근거가 된다.  

[https://arxiv.org/abs/2403.18628](https://arxiv.org/abs/2403.18628)  

### Shani, G. et al. (2012). Investigating Confidence Displays for Top-N Recommendations.  

– 추천 시스템에서 신뢰도 표시 방법과 사용자 반응에 관한 연구  

[https://tzin.bgu.ac.il/~shanigu/Publications/Confidence.JASIST.3.pdf](https://tzin.bgu.ac.il/~shanigu/Publications/Confidence.JASIST.3.pdf)  

## Reference  

[https://gemini.google.com/app/02720fa7cdb3ba6e?hl=ko](https://gemini.google.com/app/02720fa7cdb3ba6e?hl=ko)  


[https://chatgpt.com/c/697ac8b2-5f9c-8322-b709-0d7e7b299947](https://chatgpt.com/c/697ac8b2-5f9c-8322-b709-0d7e7b299947) 답변품질 낮음(비전문적)  